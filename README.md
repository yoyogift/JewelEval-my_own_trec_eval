# new_trec_eval_jewelstar_version
Puisque trec_eval mâ€™a plantÃ© comme un GPS en zone sans rÃ©seau, jâ€™ai dÃ©cidÃ© de lui faire un remake maisonâ€¯: ma propre version â€œartisanaleâ€ de trec_eval pour piloter mes expÃ©riences. RÃ©sultatâ€¯: aussi chiadÃ© quâ€™une recette de grandâ€‘mÃ¨re, mais Ã§a carbure !ğŸ¦

## ğŸ“¦ ç›®å½•ç»“æ„
```
.
â”œâ”€â”€ STARD
â”‚ â””â”€â”€ data
â”‚ â”œâ”€â”€ example
â”‚ â”‚ â””â”€â”€ dev.query.txt # å¼€å‘é›†éœ€è¦è¯„æµ‹çš„ query_id åˆ—è¡¨
â”‚ â”œâ”€â”€ corpus.jsonl # æ–‡æ¡£åº“
â”‚ â””â”€â”€ queries.json # æŸ¥è¯¢å’Œ match_name æ ‡æ³¨
â”œâ”€â”€ make_relevance_jewelstar.py # ç”Ÿæˆ relevance.jewelstar çš„è„šæœ¬
â”œâ”€â”€ make_run_jewelstar.py # ç”Ÿæˆ bm25p.run.jewelstar çš„è„šæœ¬
â”œâ”€â”€ evaluate_metrics.py # è¯„æµ‹è„šæœ¬ï¼Œè¾“å‡º recall/MRR/nDCG/P@10/MAP ç­‰
â””â”€â”€ README.md # æœ¬è¯´æ˜æ–‡ä»¶
```


## âš™ï¸ ç¯å¢ƒä¸ä¾èµ–

- Python â‰¥3.7
- pip install jieba


## 1. ç”Ÿæˆç›¸å…³æ€§æ ‡æ³¨æ–‡ä»¶ relevance.jewelstar

```
python make_relevance_jewelstar.py
```

è¯¥è„šæœ¬ä¼šè¯»å– STARD/data/example/dev.query.txt ä¸ STARD/data/queries.jsonï¼Œè¾“å‡ºå»é‡ã€æ’åºåçš„ï¼š

/<qid/> 0 /<docid/> 1'

æ ¼å¼æ–‡ä»¶ relevance.jewelstarã€‚

## 2.ç”Ÿæˆæ£€ç´¢ç»“æœæ–‡ä»¶ bm25p.run.jewelstar

```
python make_run_jewelstar.py
```

è¯¥è„šæœ¬ä¼šï¼š

- è½½å…¥ STARD/data/corpus.jsonlï¼Œå¯¹æ¯ç¯‡æ–‡æ¡£ç”¨ jieba.lcut åˆ†è¯
- è½½å…¥ STARD/data/example/dev.query.txt ä¸ STARD/data/queries.json ä¸­çš„ query
- ç”¨çº¯ Python BM25 å¯¹æ¯ä¸ª query æ’åºæ•´ä¸ªè¯­æ–™ï¼Œè¾“å‡ºï¼š

```
<qid> Q0 <docid> <rank> <score> BM25
```

åˆ° bm25p.run.jewelstarã€‚
## 3. è¯„æµ‹å¹¶è¾“å‡ºæŒ‡æ ‡

```
python evaluate_metrics.py \
  --relevance relevance.jewelstar \
  --run      bm25p.run.jewelstar
```

é»˜è®¤ä¼šè®¡ç®—å¹¶æ‰“å°ï¼š

    runidã€num_qã€num_retã€num_relã€num_rel_ret
    
    mapã€P_10
    
    recall_5ã€recall_10ã€recall_15ã€recall_20ã€recall_30ã€recall_100ã€recall_200ã€recall_500ã€recall_1000
    
    MRR (reciprocal rank)
    
    ndcg_cut_10

ç¤ºä¾‹è¾“å‡ºï¼š

```
runid all run1
num_q    all 308
num_ret  all 17047184
num_rel  all 512
num_rel_ret all 512
map      all 0.2602
P_10     all 0.0594
recall_5   all 1.0971
recall_10  all 1.8420
recall_15  all 2.5290
recall_20  all 3.1448
recall_30  all 3.6781
recall_100 all 3.8389
recall_200 all 4.2316
recall_500 all 4.5487
recall_1000 all 4.9578
MRR      all 0.3280
ndcg_cut_10 all 0.3084
```

## 4. éªŒè¯ä¸å¯¹æ¯”

è‹¥ä½ ä»å¯ä½¿ç”¨å®˜æ–¹ trec_evalï¼Œå¯å°† relevance.jewelstar é‡å‘½åä¸º qrels.trecï¼Œbm25p.run.jewelstarå‘½åä¸ºbm25p.runå¹¶ç”¨ï¼š

trec_eval -m all_qrels qrels.trec bm25p.run

æ ¸å¯¹å…³é”®æŒ‡æ ‡æ˜¯å¦å®Œå…¨ä¸€è‡´ã€‚
